mergeUserDic(data.frame(c(
"우디"
# "오케","대영","강남","나쁜남자","프사","추움","주안역",
# "일수","곱창","막창","대창","허각","변태","바이올린","비올라",
# "첼로","플룻","악장","기장","회장","부회장","총무","커플",
# "반주","긱사","자취","신입생","하드캐리","롤","개새끼","화실",
# "휴강","정석","도서관","군대","산쪼메","약사","재수강","세아랑",
# "찰칵","주모","멍충","컵밥","혼밥","핫식스","막걸리","소주",
# "술취함","오일일","기엠티","큐티","봉구스","밥집","후문","정문",
# "개꿀","셔틀","부들부들","도촬","존잘","울산","서울",
# "렌즈","두바이","정시","수능","멍청멍청","알바","으앙","주금",
# "노답","고찜","동방","양아치","조칼","존잼","졸환","신환","정연",
# "음캠","연돌","샤태톰","세빈니뮤","현정니뮤","인천","송도",
# "부천","워홀","어학연수","수강신청","돈참","성광교회","화이팅"
# "꿀잼","꾸르잼","민주화","일베","노잼","닥전",
# "닥후","메갈","보지화","개이득","김치녀","인정",
# "민주화","메갈리아","페미니스트","페미","맘충",
# "탈조선","헬반도","천조국","자야겠","굿나잇",
# "잘자라","와이","왜인가","와진","의리남","비의리남",
# "자는가","조타","소울","미팅","소개팅","지하철","통금",
# "읽씹","휴가","레지","엠티","픽스","동아리","군기",
# "레지던트","여친","여자친구","핵고통","유급","춘천",
# "셀카봉","섹스","바보","이마트","입실렌티","라인업",
# "아재","피시방","pc방","방탈출","범계","쉑쉑버거",
# "오버워치","평촌","무한리필","댄스","고대","한림대",
# "어플","스키장","자취방","집들이","1박2일","선약",
# "예과","본과","씹노잼","퀴즈","과제","시험기간"
), "ncn"))
library(KoNLP)
mergeUserDic(data.frame(c(
"우디"
# "오케","대영","강남","나쁜남자","프사","추움","주안역",
# "일수","곱창","막창","대창","허각","변태","바이올린","비올라",
# "첼로","플룻","악장","기장","회장","부회장","총무","커플",
# "반주","긱사","자취","신입생","하드캐리","롤","개새끼","화실",
# "휴강","정석","도서관","군대","산쪼메","약사","재수강","세아랑",
# "찰칵","주모","멍충","컵밥","혼밥","핫식스","막걸리","소주",
# "술취함","오일일","기엠티","큐티","봉구스","밥집","후문","정문",
# "개꿀","셔틀","부들부들","도촬","존잘","울산","서울",
# "렌즈","두바이","정시","수능","멍청멍청","알바","으앙","주금",
# "노답","고찜","동방","양아치","조칼","존잼","졸환","신환","정연",
# "음캠","연돌","샤태톰","세빈니뮤","현정니뮤","인천","송도",
# "부천","워홀","어학연수","수강신청","돈참","성광교회","화이팅"
# "꿀잼","꾸르잼","민주화","일베","노잼","닥전",
# "닥후","메갈","보지화","개이득","김치녀","인정",
# "민주화","메갈리아","페미니스트","페미","맘충",
# "탈조선","헬반도","천조국","자야겠","굿나잇",
# "잘자라","와이","왜인가","와진","의리남","비의리남",
# "자는가","조타","소울","미팅","소개팅","지하철","통금",
# "읽씹","휴가","레지","엠티","픽스","동아리","군기",
# "레지던트","여친","여자친구","핵고통","유급","춘천",
# "셀카봉","섹스","바보","이마트","입실렌티","라인업",
# "아재","피시방","pc방","방탈출","범계","쉑쉑버거",
# "오버워치","평촌","무한리필","댄스","고대","한림대",
# "어플","스키장","자취방","집들이","1박2일","선약",
# "예과","본과","씹노잼","퀴즈","과제","시험기간"
), "ncn"))
# install.packages("googleVis")
# install.packages("igraph")
install.packages("qgraph",dep=TRUE)
library(qgraph) # 연관성 결과 시각화 그래프
packageDescription('qgraph')$Version
options(
qgraph = list(
border.width = 2,
asize = 8,
unCol = "black",
vsize = 10,
esize = 3)
)
input <- matrix(c(
0,1,1,
0,0,1,
0,0,0),3,3,byrow=TRUE)
print(input)
qgraph(input)
input <- matrix(0,8,8)
input[1,2] <- 1
input[2,3] <- 1
input[3,4] <- 1
input[4,5] <- 1
input[5,6] <- 1
input[6,7] <- 1
input[7,8] <- 1
input[8,1] <- 1
print(input)
dout(intput)
dput(intput)
dput(input)
input<- matrix(1,3,3)
print(input)
qgraph(input,directed=TRUE)
input<-matrix(c(
0,1,2,
0,0,3,
0,0,0),3,3,byrow=TRUE)
qgraph(input)
data(big5)
str(big5)
print(big5)
View(big5)
qgraph(cor(big5),minimum=0.25)
install.packages("RCurl")
save.image("~/.RData")
setwd("D:/Workspace/R_Workspace/Data/chapter 4")
# sms data 불러오기
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE, encoding="UTF-8")
# 오류데이터 수정
sms_raw$text[1072] <- sms_raw$type[1072]
sms_raw$type[1072] <- "ham"
# convert spam/ham to factor. type 자료형을 character -> factor 로 변환
sms_raw$type <- factor(sms_raw$type)
# Cleaning 전처리 작업
replacePuctuation2space <- function(x){gsub("[[:punct:]]+", " ", x)}
sms_raw$text <- replacePuctuation2space(sms_raw$text)
# ...이전 이후의 단어가 서로 붙는것을 방지
rm(replacePuctuation2space)
# build a corpus using the text mining (tm) package
library(tm)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
# clean up the corpus using tm_map()
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_matrix <- as.matrix(sms_dtm)
sms_df <- as.data.frame(sms_matrix)
all_sum <- as.data.frame(colSums(sms_df),
row.names=NULL,
col.names=colnames(sms_df))
View(all_sum)
all_sum <- as.data.frame(colSums(sms_df))#,
# row.names=NULL,
# col.names=colnames(sms_df))
View(all_sum)
# row.names=NULL,
# col.names=colnames(sms_df))
View(all_sum)
all_sum <- as.data.frame(colSums(sms_df), col.names="count")
View(all_sum)
all_sum <- as.data.frame(colSums(sms_df))
sms_df <- cbind(sms_df, sms_raw$type)
sms_df_top <- sms_df[,-which(all_sum < 80)]
sms_df <- as.data.frame(sms_matrix)
str(sms_df)
View(classify_word)
# 각 spamham rate 계산 후 단어별 ditance 도출
type_col <- ncol(sms_df_top)
count <- colSums(sms_df_top[-type_col])
spam_sum <- colSums(subset(sms_df_top[-type_col],sms_raw$type == "spam"))
ham_sum <- colSums(subset(sms_df_top[-type_col],sms_raw$type == "ham"))
spam_rate <- spam_sum/count
ham_rate <- ham_sum/count
distance <- abs(spam_rate-ham_rate)
classify_word <- cbind(distance, spam_rate, ham_rate,count)
View(classify_word)
View(result)
important_word <- head(rownames(classify_word[order(-distance),]),10)
most_spam_word <- head(rownames(classify_word[order(-spam_rate),]),10)
most_ham_word  <- head(rownames(classify_word[order(-ham_rate),]),10)
most_cnt_word  <- head(rownames(classify_word[order(-count),]),10)
distance10  <- round(classify_word[order(-distance),][1:10,1], digits = 2)
spam_rate10 <- round(classify_word[order(-spam_rate),][1:10,2], digits = 2)
ham_rate10  <- round(classify_word[order(-ham_rate),][1:10,3], digits = 2)
result <- cbind(important_word,distance10,most_spam_word,spam_rate10,
most_ham_word,ham_rate10,most_cnt_word,count10)
colnames(result) <- c("important_word","dist","most_spam_word","rate",
"most_ham_word","rate","most_cnt_word","count")
View(result)
count10     <- round(classify_word[order(-count),][1:10,4], digits = 2)
important_word <- head(rownames(classify_word[order(-distance),]),10)
most_spam_word <- head(rownames(classify_word[order(-spam_rate),]),10)
most_ham_word  <- head(rownames(classify_word[order(-ham_rate),]),10)
most_cnt_word  <- head(rownames(classify_word[order(-count),]),10)
distance10  <- round(classify_word[order(-distance),][1:10,1], digits = 2)
spam_rate10 <- round(classify_word[order(-spam_rate),][1:10,2], digits = 2)
ham_rate10  <- round(classify_word[order(-ham_rate),][1:10,3], digits = 2)
count10     <- round(classify_word[order(-count),][1:10,4], digits = 2)
result <- cbind(important_word,distance10,most_spam_word,spam_rate10,
most_ham_word,ham_rate10,most_cnt_word,count10)
colnames(result) <- c("important_word","dist","most_spam_word","rate",
"most_ham_word","rate","most_cnt_word","count")
View(result)
